{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trialing a pipeline \n",
    "\n",
    "Here we want to create a trial pipleine , in this trial pipeline we will have random integers the goal is to get out model to output some scores for a couple pipes basically for now they can be random integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example model to run for now just to get an idea \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TowerOne(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TowerOne, self).__init__()\n",
    "        \n",
    "        # First layer: input 64 features, output 32 features\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        \n",
    "        # Second layer: input 32 features, output 16 features\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        \n",
    "        # Third layer: input 16 features, output 3 features (final output)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "        # Activation function (ReLU) applied after first and second layers\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the first layer, followed by ReLU\n",
    "        x = self.relu(self.fc1(x))\n",
    "        \n",
    "        # Pass through the second layer, followed by ReLU\n",
    "        x = self.relu(self.fc2(x))\n",
    "        \n",
    "        # Pass through the final layer to get 3 output features\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TowerTwo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TowerTwo, self).__init__()\n",
    "        self.fc = nn.Linear(64, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video input: tensor([[0.4139, 0.7380, 0.2999, 0.3325, 0.0293, 0.4814, 0.3391, 0.9069, 0.7763,\n",
      "         0.0498, 0.5203, 0.0422, 0.3766, 0.6510, 0.6568, 0.4529, 0.9977, 0.2522,\n",
      "         0.9066, 0.0753, 0.8177, 0.1161, 0.6997, 0.4761, 0.5777, 0.1587, 0.9614,\n",
      "         0.5546, 0.4156, 0.5668, 0.9692, 0.1272, 0.5269, 0.8872, 0.6158, 0.8411,\n",
      "         0.7299, 0.1364, 0.8546, 0.0254, 0.3160, 0.8907, 0.3916, 0.0663, 0.2259,\n",
      "         0.9908, 0.0894, 0.6401, 0.2493, 0.8152, 0.6204, 0.2751, 0.6881, 0.4009,\n",
      "         0.7173, 0.4172, 0.1987, 0.7279, 0.9791, 0.4464, 0.2679, 0.2666, 0.5608,\n",
      "         0.2206]])\n",
      "Query input: tensor([[0.2647, 0.4808, 0.9866]])\n",
      "Output from TowerOne: tensor([[-0.0077,  0.0032, -0.2654]], grad_fn=<AddmmBackward0>)\n",
      "Output from TowerTwo: tensor([[-0.4474,  0.2700,  0.4150]], grad_fn=<AddmmBackward0>)\n",
      "Cosine similarity score: tensor([-0.5973], grad_fn=<SumBackward1>)\n",
      "Loss: tensor(2.5513, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate random inputs\n",
    "video = torch.rand(1, 64)\n",
    "video = torch.rand(1, 64)\n",
    "video = torch.rand(1, 64)\n",
    "video = torch.rand(1, 64)\n",
    "\n",
    "\n",
    "query = torch.rand(1, 3)   # Input for TowerTwo\n",
    "\n",
    "# Initialize models\n",
    "tower_one = TowerOne()\n",
    "tower_two = TowerTwo()\n",
    "\n",
    "# Forward pass through both towers\n",
    "output_one = tower_one(video)  # Pass video through TowerOne\n",
    "output_two = tower_two(query)  # Pass query through TowerTwo\n",
    "\n",
    "# Compute cosine similarity between the outputs\n",
    "score = nn.functional.cosine_similarity(output_one, output_two, dim=1)\n",
    "\n",
    "# Define target and compute loss (mean squared error)\n",
    "target = torch.tensor([1.0])  # The target cosine similarity\n",
    "loss = (score - target).pow(2).mean()\n",
    "\n",
    "# Backpropagation\n",
    "loss.backward()\n",
    "\n",
    "# Print outputs for debugging\n",
    "print(\"Video input:\", video)\n",
    "print(\"Query input:\", query)\n",
    "print(\"Output from TowerOne:\", output_one)\n",
    "print(\"Output from TowerTwo:\", output_two)\n",
    "print(\"Cosine similarity score:\", score)\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor output: tensor([[-0.1423, -0.1539,  0.1909]], grad_fn=<AddmmBackward0>)\n",
      "Positive 1 output: tensor([[-0.2249,  0.2396,  0.2570]], grad_fn=<AddmmBackward0>)\n",
      "Positive 2 output: tensor([[-0.6124,  0.3555,  0.0086]], grad_fn=<AddmmBackward0>)\n",
      "Negative 1 output: tensor([[-0.4607,  0.0852,  0.0928]], grad_fn=<AddmmBackward0>)\n",
      "Negative 2 output: tensor([[-0.3622,  0.3388,  0.0395]], grad_fn=<AddmmBackward0>)\n",
      "Cosine similarity positive 1: tensor([0.3736], grad_fn=<SumBackward1>)\n",
      "Cosine similarity positive 2: tensor([0.1697], grad_fn=<SumBackward1>)\n",
      "Cosine similarity negative 1: tensor([0.5182], grad_fn=<SumBackward1>)\n",
      "Cosine similarity negative 2: tensor([0.0493], grad_fn=<SumBackward1>)\n",
      "Triplet loss: tensor(2.0242, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define margin for triplet loss\n",
    "margin = 1.0\n",
    "\n",
    "\n",
    "positive_video1 = torch.rand(1, 64)\n",
    "positive_video2 = torch.rand(1, 64)\n",
    "negative_video1 = torch.rand(1, 64)\n",
    "negative_video2 = torch.rand(1, 64)\n",
    "\n",
    "anchor_query = torch.rand(1, 64)  # Input for TowerTwo (optional for your task)\n",
    "\n",
    "# Initialize models\n",
    "tower_one = TowerOne()\n",
    "tower_two = TowerTwo()\n",
    "\n",
    "# Forward pass through the tower for each video\n",
    "anchor_output = tower_one(anchor_query)          # Anchor\n",
    "positive_output1 = tower_two(positive_video1)    # Positive sample 1\n",
    "positive_output2 = tower_two(positive_video2)    # Positive sample 2\n",
    "negative_output1 = tower_two(negative_video1)    # Negative sample 1\n",
    "negative_output2 = tower_two(negative_video2)    # Negative sample 2\n",
    "\n",
    "# Cosine similarity between anchor and positives\n",
    "cosine_sim_positive1 = nn.functional.cosine_similarity(anchor_output, positive_output1, dim=1)\n",
    "cosine_sim_positive2 = nn.functional.cosine_similarity(anchor_output, positive_output2, dim=1)\n",
    "\n",
    "\n",
    "# Cosine similarity between anchor and negatives\n",
    "cosine_sim_negative1 = nn.functional.cosine_similarity(anchor_output, negative_output1, dim=1)\n",
    "cosine_sim_negative2 = nn.functional.cosine_similarity(anchor_output, negative_output2, dim=1)\n",
    "\n",
    "# Compute Triplet Loss (for positive1-negative1 and positive2-negative2)\n",
    "triplet_loss1 = torch.clamp(margin - cosine_sim_positive1 + cosine_sim_negative1, min=0)\n",
    "triplet_loss2 = torch.clamp(margin - cosine_sim_positive2 + cosine_sim_negative2, min=0)\n",
    "\n",
    "# Average the losses\n",
    "triplet_loss = (triplet_loss1 + triplet_loss2).mean()\n",
    "\n",
    "# Backpropagation\n",
    "triplet_loss.backward()\n",
    "\n",
    "# Print debugging information\n",
    "print(\"Anchor output:\", anchor_output)\n",
    "print(\"Positive 1 output:\", positive_output1)\n",
    "print(\"Positive 2 output:\", positive_output2)\n",
    "print(\"Negative 1 output:\", negative_output1)\n",
    "print(\"Negative 2 output:\", negative_output2)\n",
    "print(\"Cosine similarity positive 1:\", cosine_sim_positive1)\n",
    "print(\"Cosine similarity positive 2:\", cosine_sim_positive2)\n",
    "print(\"Cosine similarity negative 1:\", cosine_sim_negative1)\n",
    "print(\"Cosine similarity negative 2:\", cosine_sim_negative2)\n",
    "print(\"Triplet loss:\", triplet_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1000/1000 [00:02<00:00, 423.17epoch/s, Triplet Loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Define the margin for triplet loss\n",
    "margin = 1.0\n",
    "num_epochs = 1000  # Number of iterations/epochs to run\n",
    "learning_rate = 0.001  # Learning rate for optimizer\n",
    "batch_size = 16  # Batch size for training\n",
    "\n",
    "# Initialize models (Make sure TowerOne and TowerTwo are defined)\n",
    "tower_one = TowerOne()\n",
    "tower_two = TowerTwo()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(list(tower_one.parameters()) + list(tower_two.parameters()), lr=learning_rate)\n",
    "\n",
    "# TripletMarginWithDistanceLoss with cosine similarity as the distance function\n",
    "triplet_loss_fn = nn.TripletMarginWithDistanceLoss(\n",
    "    distance_function=lambda x, y: 1.0 - nn.functional.cosine_similarity(x, y),\n",
    "    margin=margin\n",
    ")\n",
    "\n",
    "# Training loop with tqdm for progress tracking\n",
    "with tqdm(total=num_epochs, desc=\"Training Progress\", unit=\"epoch\") as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        # Generate random batches of video inputs (batch size anchor, 2 positive, 2 negative)\n",
    "        anchor_query = torch.rand(batch_size, 64)    # Anchor batch\n",
    "        positive_video1 = torch.rand(batch_size, 64) # Positive batch 1\n",
    "        positive_video2 = torch.rand(batch_size, 64) # Positive batch 2\n",
    "        negative_video1 = torch.rand(batch_size, 64) # Negative batch 1\n",
    "        negative_video2 = torch.rand(batch_size, 64) # Negative batch 2\n",
    "        \n",
    "        # Zero gradients (reset gradients before backpropagation)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the tower for each video batch\n",
    "        anchor_output = tower_one(anchor_query)          # Anchor\n",
    "        positive_output1 = tower_two(positive_video1)    # Positive sample 1\n",
    "        positive_output2 = tower_two(positive_video2)    # Positive sample 2\n",
    "        negative_output1 = tower_two(negative_video1)    # Negative sample 1\n",
    "        negative_output2 = tower_two(negative_video2)    # Negative sample 2\n",
    "\n",
    "        # Calculate triplet loss using custom cosine similarity distance\n",
    "        triplet_loss1 = triplet_loss_fn(anchor_output, positive_output1, negative_output1)\n",
    "        triplet_loss2 = triplet_loss_fn(anchor_output, positive_output2, negative_output2)\n",
    "\n",
    "        # Average the triplet losses\n",
    "        triplet_loss = (triplet_loss1 + triplet_loss2) / 2\n",
    "\n",
    "        # Backpropagation\n",
    "        triplet_loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tqdm description with current loss\n",
    "        pbar.set_postfix({\"Triplet Loss\": triplet_loss.item()})\n",
    "        pbar.update(1)  # Increment the progress bar\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
