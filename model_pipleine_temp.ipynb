{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example model to run for now just to get an idea \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trialing a pipeline \n",
    "\n",
    "Here we want to create a trial pipleine , in this trial pipeline we will have random integers the goal is to get out model to output some scores for a couple pipes basically for now they can be random integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example model to run for now just to get an idea \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TowerOne(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TowerOne, self).__init__()\n",
    "        \n",
    "        # First layer: input 64 features, output 32 features\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        \n",
    "        # Second layer: input 32 features, output 16 features\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        \n",
    "        # Third layer: input 16 features, output 3 features (final output)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        \n",
    "        # Activation function (ReLU) applied after first and second layers\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through the first layer, followed by ReLU\n",
    "        x = self.relu(self.fc1(x))\n",
    "        \n",
    "        # Pass through the second layer, followed by ReLU\n",
    "        x = self.relu(self.fc2(x))\n",
    "        \n",
    "        # Pass through the final layer to get 3 output features\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TowerTwo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TowerTwo, self).__init__()\n",
    "        self.fc = nn.Linear(64, 3)\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video input: tensor([[0.4139, 0.7380, 0.2999, 0.3325, 0.0293, 0.4814, 0.3391, 0.9069, 0.7763,\n",
      "         0.0498, 0.5203, 0.0422, 0.3766, 0.6510, 0.6568, 0.4529, 0.9977, 0.2522,\n",
      "         0.9066, 0.0753, 0.8177, 0.1161, 0.6997, 0.4761, 0.5777, 0.1587, 0.9614,\n",
      "         0.5546, 0.4156, 0.5668, 0.9692, 0.1272, 0.5269, 0.8872, 0.6158, 0.8411,\n",
      "         0.7299, 0.1364, 0.8546, 0.0254, 0.3160, 0.8907, 0.3916, 0.0663, 0.2259,\n",
      "         0.9908, 0.0894, 0.6401, 0.2493, 0.8152, 0.6204, 0.2751, 0.6881, 0.4009,\n",
      "         0.7173, 0.4172, 0.1987, 0.7279, 0.9791, 0.4464, 0.2679, 0.2666, 0.5608,\n",
      "         0.2206]])\n",
      "Query input: tensor([[0.2647, 0.4808, 0.9866]])\n",
      "Output from TowerOne: tensor([[-0.0077,  0.0032, -0.2654]], grad_fn=<AddmmBackward0>)\n",
      "Output from TowerTwo: tensor([[-0.4474,  0.2700,  0.4150]], grad_fn=<AddmmBackward0>)\n",
      "Cosine similarity score: tensor([-0.5973], grad_fn=<SumBackward1>)\n",
      "Loss: tensor(2.5513, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#call embedder\n",
    "\n",
    "\n",
    "# Generate random inputs\n",
    "video = torch.rand(1, 64)\n",
    "video = torch.rand(1, 64)\n",
    "video = torch.rand(1, 64)\n",
    "video = torch.rand(1, 64)\n",
    "\n",
    "\n",
    "query = torch.rand(1, 3)   # Input for TowerTwo\n",
    "\n",
    "# Initialize models\n",
    "tower_one = TowerOne()\n",
    "tower_two = TowerTwo()\n",
    "\n",
    "# Forward pass through both towers\n",
    "output_one = tower_one(video)  # Pass video through TowerOne\n",
    "output_two = tower_two(query)  # Pass query through TowerTwo\n",
    "\n",
    "# Compute cosine similarity between the outputs\n",
    "score = nn.functional.cosine_similarity(output_one, output_two, dim=1)\n",
    "\n",
    "# Define target and compute loss (mean squared error)\n",
    "target = torch.tensor([1.0])  # The target cosine similarity\n",
    "loss = (score - target).pow(2).mean()\n",
    "\n",
    "# Backpropagation\n",
    "loss.backward()\n",
    "\n",
    "# Print outputs for debugging\n",
    "print(\"Video input:\", video)\n",
    "print(\"Query input:\", query)\n",
    "print(\"Output from TowerOne:\", output_one)\n",
    "print(\"Output from TowerTwo:\", output_two)\n",
    "print(\"Cosine similarity score:\", score)\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor output: tensor([[-0.1423, -0.1539,  0.1909]], grad_fn=<AddmmBackward0>)\n",
      "Positive 1 output: tensor([[-0.2249,  0.2396,  0.2570]], grad_fn=<AddmmBackward0>)\n",
      "Positive 2 output: tensor([[-0.6124,  0.3555,  0.0086]], grad_fn=<AddmmBackward0>)\n",
      "Negative 1 output: tensor([[-0.4607,  0.0852,  0.0928]], grad_fn=<AddmmBackward0>)\n",
      "Negative 2 output: tensor([[-0.3622,  0.3388,  0.0395]], grad_fn=<AddmmBackward0>)\n",
      "Cosine similarity positive 1: tensor([0.3736], grad_fn=<SumBackward1>)\n",
      "Cosine similarity positive 2: tensor([0.1697], grad_fn=<SumBackward1>)\n",
      "Cosine similarity negative 1: tensor([0.5182], grad_fn=<SumBackward1>)\n",
      "Cosine similarity negative 2: tensor([0.0493], grad_fn=<SumBackward1>)\n",
      "Triplet loss: tensor(2.0242, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define margin for triplet loss\n",
    "margin = 1.0\n",
    "\n",
    "\n",
    "positive_video1 = torch.rand(1, 64)\n",
    "positive_video2 = torch.rand(1, 64)\n",
    "negative_video1 = torch.rand(1, 64)\n",
    "negative_video2 = torch.rand(1, 64)\n",
    "\n",
    "anchor_query = torch.rand(1, 64)  # Input for TowerTwo (optional for your task)\n",
    "\n",
    "# Initialize models\n",
    "tower_one = TowerOne()\n",
    "tower_two = TowerTwo()\n",
    "\n",
    "# Forward pass through the tower for each video\n",
    "anchor_output = tower_one(anchor_query)          # Anchor\n",
    "positive_output1 = tower_two(positive_video1)    # Positive sample 1\n",
    "positive_output2 = tower_two(positive_video2)    # Positive sample 2\n",
    "negative_output1 = tower_two(negative_video1)    # Negative sample 1\n",
    "negative_output2 = tower_two(negative_video2)    # Negative sample 2\n",
    "\n",
    "# Cosine similarity between anchor and positives\n",
    "cosine_sim_positive1 = nn.functional.cosine_similarity(anchor_output, positive_output1, dim=1)\n",
    "cosine_sim_positive2 = nn.functional.cosine_similarity(anchor_output, positive_output2, dim=1)\n",
    "\n",
    "\n",
    "# Cosine similarity between anchor and negatives\n",
    "cosine_sim_negative1 = nn.functional.cosine_similarity(anchor_output, negative_output1, dim=1)\n",
    "cosine_sim_negative2 = nn.functional.cosine_similarity(anchor_output, negative_output2, dim=1)\n",
    "\n",
    "# Compute Triplet Loss (for positive1-negative1 and positive2-negative2)\n",
    "triplet_loss1 = torch.clamp(margin - cosine_sim_positive1 + cosine_sim_negative1, min=0)\n",
    "triplet_loss2 = torch.clamp(margin - cosine_sim_positive2 + cosine_sim_negative2, min=0)\n",
    "\n",
    "# Average the losses\n",
    "triplet_loss = (triplet_loss1 + triplet_loss2).mean()\n",
    "\n",
    "# Backpropagation\n",
    "triplet_loss.backward()\n",
    "\n",
    "# Print debugging information\n",
    "print(\"Anchor output:\", anchor_output)\n",
    "print(\"Positive 1 output:\", positive_output1)\n",
    "print(\"Positive 2 output:\", positive_output2)\n",
    "print(\"Negative 1 output:\", negative_output1)\n",
    "print(\"Negative 2 output:\", negative_output2)\n",
    "print(\"Cosine similarity positive 1:\", cosine_sim_positive1)\n",
    "print(\"Cosine similarity positive 2:\", cosine_sim_positive2)\n",
    "print(\"Cosine similarity negative 1:\", cosine_sim_negative1)\n",
    "print(\"Cosine similarity negative 2:\", cosine_sim_negative2)\n",
    "print(\"Triplet loss:\", triplet_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 1000/1000 [00:02<00:00, 423.17epoch/s, Triplet Loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Define the margin for triplet loss\n",
    "margin = 1.0\n",
    "num_epochs = 1000  # Number of iterations/epochs to run\n",
    "learning_rate = 0.001  # Learning rate for optimizer\n",
    "batch_size = 16  # Batch size for training\n",
    "\n",
    "# Initialize models (Make sure TowerOne and TowerTwo are defined)\n",
    "tower_one = TowerOne()\n",
    "tower_two = TowerTwo()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(list(tower_one.parameters()) + list(tower_two.parameters()), lr=learning_rate)\n",
    "\n",
    "# TripletMarginWithDistanceLoss with cosine similarity as the distance function\n",
    "triplet_loss_fn = nn.TripletMarginWithDistanceLoss(\n",
    "    distance_function=lambda x, y: 1.0 - nn.functional.cosine_similarity(x, y),\n",
    "    margin=margin\n",
    ")\n",
    "\n",
    "# Training loop with tqdm for progress tracking\n",
    "with tqdm(total=num_epochs, desc=\"Training Progress\", unit=\"epoch\") as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        # Generate random batches of video inputs (batch size anchor, 2 positive, 2 negative)\n",
    "        anchor_query = torch.rand(batch_size, 64)    # Anchor batch\n",
    "        positive_video1 = torch.rand(batch_size, 64) # Positive batch 1\n",
    "        positive_video2 = torch.rand(batch_size, 64) # Positive batch 2\n",
    "        negative_video1 = torch.rand(batch_size, 64) # Negative batch 1\n",
    "        negative_video2 = torch.rand(batch_size, 64) # Negative batch 2\n",
    "        \n",
    "        # Zero gradients (reset gradients before backpropagation)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the tower for each video batch\n",
    "        anchor_output = tower_one(anchor_query)          # Anchor\n",
    "        positive_output1 = tower_two(positive_video1)    # Positive sample 1\n",
    "        positive_output2 = tower_two(positive_video2)    # Positive sample 2\n",
    "        negative_output1 = tower_two(negative_video1)    # Negative sample 1\n",
    "        negative_output2 = tower_two(negative_video2)    # Negative sample 2\n",
    "\n",
    "        # Calculate triplet loss using custom cosine similarity distance\n",
    "        triplet_loss1 = triplet_loss_fn(anchor_output, positive_output1, negative_output1)\n",
    "        triplet_loss2 = triplet_loss_fn(anchor_output, positive_output2, negative_output2)\n",
    "\n",
    "        # Average the triplet losses\n",
    "        triplet_loss = (triplet_loss1 + triplet_loss2) / 2\n",
    "\n",
    "        # Backpropagation\n",
    "        triplet_loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update tqdm description with current loss\n",
    "        pbar.set_postfix({\"Triplet Loss\": triplet_loss.item()})\n",
    "        pbar.update(1)  # Increment the progress bar\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying out model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example model to run for now just to get an idea \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramFoo(torch.nn.Module):\n",
    "  def __init__(self, voc, emb, ctx):\n",
    "    super().__init__()\n",
    "    self.ctx = ctx\n",
    "    self.emb = torch.nn.Embedding(num_embeddings=voc, embedding_dim=emb)\n",
    "    self.ffw = torch.nn.Linear(in_features=emb, out_features=voc, bias=False)\n",
    "    self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "  # def forward(self, inpt, trgs, rand):\n",
    "  #   emb = self.emb(inpt)\n",
    "  #   ctx = self.ffw.weight[trgs]\n",
    "  #   rnd = self.ffw.weight[rand]\n",
    "  #   out = torch.mm(ctx, emb.T)\n",
    "  #   rnd = torch.mm(rnd, emb.T)\n",
    "  #   out = self.sig(out).clamp(min=1e-7, max=1 - 1e-7)\n",
    "  #   rnd = self.sig(rnd).clamp(min=1e-7, max=1 - 1e-7)\n",
    "  #   pst = -out.log().mean()\n",
    "  #   ngt = -(1 - rnd).log().mean()\n",
    "  #   return pst + ngt\n",
    "\n",
    "#new forwarding for batch size \n",
    "  def forward(self, inpt, trgs, rand):\n",
    "    # Embedding lookup for input (shape: [batch_size, embedding_dim])\n",
    "    emb = self.emb(inpt)\n",
    "    \n",
    "    # Ensure context (trgs) and random samples (rand) have the same batch size as inpt\n",
    "    batch_size = inpt.size(0)  # Get the current batch size\n",
    "\n",
    "    # Slice or generate the random tensor according to the input batch size\n",
    "    rand = rand[:batch_size]  # Adjust random tensor to match current batch size\n",
    "    \n",
    "    ctx = self.ffw.weight[trgs.to(inpt.device)]  # Shape: [batch_size, 2, embedding_dim]\n",
    "    rnd = self.ffw.weight[rand.to(inpt.device)]  # Shape: [batch_size, 2, embedding_dim]\n",
    "\n",
    "    # Ensure the batch size matches before performing batch matrix multiplication\n",
    "    assert ctx.size(0) == emb.size(0), f\"Context batch size {ctx.size(0)} doesn't match embeddings batch size {emb.size(0)}\"\n",
    "    assert rnd.size(0) == emb.size(0), f\"Random batch size {rnd.size(0)} doesn't match embeddings batch size {emb.size(0)}\"\n",
    "    \n",
    "    # Perform batch matrix multiplication\n",
    "    out = torch.bmm(ctx, emb.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, 2)\n",
    "    rnd = torch.bmm(rnd, emb.unsqueeze(2)).squeeze(2)  # Shape: (batch_size, 2)\n",
    "    \n",
    "    # Apply sigmoid and clamp to prevent NaNs\n",
    "    out = self.sig(out).clamp(min=1e-7, max=1 - 1e-7)\n",
    "    rnd = self.sig(rnd).clamp(min=1e-7, max=1 - 1e-7)\n",
    "\n",
    "    # Calculate loss\n",
    "    pst = -out.log().mean()   # Positive sample log-likelihood\n",
    "    ngt = -(1 - rnd).log().mean()  # Negative sample log-likelihood\n",
    "    \n",
    "    return pst + ngt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkipGramFoo(\n",
       "  (emb): Embedding(70572, 64)\n",
       "  (ffw): Linear(in_features=64, out_features=70572, bias=False)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create an instance of your model\n",
    "model_path = \"skipgram_model_titles.pth\"\n",
    "mfoo = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "mfoo = SkipGramFoo(voc=70572, emb=64, ctx=2)  # Initialize with proper params\n",
    "mfoo.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "mfoo.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in dataset of passages to add to dictionary \n",
    "extra_voc = pd.read_csv('extra_dict.csv')\n",
    "new_words = extra_voc['passage_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "\n",
    "def preprocess(text: str) -> list[str]:\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace punctuation with placeholders\n",
    "    text = text.replace('.',  ' <PERIOD> ')\n",
    "    text = text.replace(',',  ' <COMMA> ')\n",
    "    text = text.replace('\"',  ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';',  ' <SEMICOLON> ')\n",
    "    text = text.replace('!',  ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?',  ' <QUESTION_MARK> ')\n",
    "    text = text.replace('(',  ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')',  ' <RIGHT_PAREN> ')\n",
    "    text = text.replace('--', ' <HYPHENS> ')\n",
    "    text = text.replace(':',  ' <COLON> ')\n",
    "\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Count occurrences of each word\n",
    "    stats = collections.Counter(words)\n",
    "    \n",
    "    # Filter words to keep only those that occur more than 15 times\n",
    "    words = [word for word in words if stats[word] > 15]\n",
    "    \n",
    "    # Remove any remaining symbols (non-alphabetic characters)\n",
    "    words = [word for word in words if re.match(r'^[a-zA-Z<>\\s]+$', word)]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Convert the Pandas Series to a list\n",
    "new_words = new_words.tolist()  \n",
    "\n",
    "# Now call your preprocess function\n",
    "new_words = preprocess(' '.join(new_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols found: Counter({'<': 6075090, '>': 6075090})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "def identify_symbols(text) -> list[str]:\n",
    "    # If text is a list, join it into a single string\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "    # Use regex to find non-alphabetic characters\n",
    "    symbols = re.findall(r'[^a-zA-Z\\s]', text)\n",
    "    \n",
    "    # Count the occurrences of each symbol\n",
    "    symbol_counts = collections.Counter(symbols)\n",
    "    \n",
    "    return symbol_counts\n",
    "\n",
    "\n",
    "# Identify symbols in the list of words\n",
    "symbols = identify_symbols(new_words)\n",
    "\n",
    "print(\"Symbols found:\", symbols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70572\n",
      "121598\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load existing vocabulary\n",
    "import pickle\n",
    "\n",
    "with open(\"vocab_dict.pkl\", \"rb\") as f:\n",
    "    vocab_dict = pickle.load(f)\n",
    "\n",
    "print(len(vocab_dict))\n",
    "\n",
    "for word in new_words:\n",
    "    if word not in vocab_dict:\n",
    "        vocab_dict[word] = len(vocab_dict)  # Assign new index\n",
    "\n",
    "print(len(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicated words found.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Invert vocab_dict to detect duplicates (word -> list of IDs)\n",
    "inverted_vocab = defaultdict(list)\n",
    "\n",
    "# Fill the inverted dictionary (key: word, value: list of IDs)\n",
    "for word_id, word in vocab_dict.items():\n",
    "    inverted_vocab[word].append(word_id)\n",
    "\n",
    "# Check for duplicated words\n",
    "duplicated_words = {word: ids for word, ids in inverted_vocab.items() if len(ids) > 1}\n",
    "\n",
    "# Display the duplicated words and their IDs\n",
    "if duplicated_words:\n",
    "    print(\"Duplicated Words Found:\")\n",
    "    for word, ids in duplicated_words.items():\n",
    "        print(f\"Word: '{word}' has multiple IDs: {ids}\")\n",
    "else:\n",
    "    print(\"No duplicated words found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list of token IDs corresponding to the new words\n",
    "new_token_ids = []\n",
    "\n",
    "for word in new_words:\n",
    "    if word in vocab_dict:\n",
    "        new_token_ids.append(vocab_dict[word])  # Get the ID from the vocabulary dictionary\n",
    "    else:\n",
    "        print(f\"Warning: '{word}' not found in the vocabulary dictionary.\")  # Optional: handle missing words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Vocabulary Size: 70572\n",
      "New Vocabulary Size: 179541\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "print(f\"Old Vocabulary Size: {old_vocab_size}\")\n",
    "print(f\"New Vocabulary Size: {new_vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming mfoo is already defined and is your SkipGram model\n",
    "\n",
    "# Get old vocabulary size and embedding dimension\n",
    "old_vocab_size = 70572  # Your old vocab size\n",
    "new_vocab_size = 179541 # Your new vocab size\n",
    "embedding_dim = mfoo.emb.embedding_dim  # Get the embedding dimension\n",
    "\n",
    "# Create a new embedding layer with the new vocabulary size\n",
    "new_embedding_layer = torch.nn.Embedding(new_vocab_size, embedding_dim)\n",
    "\n",
    "# Copy old weights to the new layer, ensuring you do not exceed the size\n",
    "if old_vocab_size <= new_vocab_size:\n",
    "    new_embedding_layer.weight.data[:old_vocab_size] = mfoo.emb.weight.data[:old_vocab_size]\n",
    "\n",
    "# Initialize the new weights for the newly added words (if desired)\n",
    "new_embedding_layer.weight.data[old_vocab_size:] = torch.randn(new_vocab_size - old_vocab_size, embedding_dim)\n",
    "\n",
    "# Replace the old embedding layer with the new one\n",
    "mfoo.emb = new_embedding_layer\n",
    "\n",
    "# Update the Linear Layer (self.ffw) to handle the new vocabulary size\n",
    "new_ffw_layer = torch.nn.Linear(in_features=embedding_dim, out_features=new_vocab_size, bias=False)\n",
    "\n",
    "# Copy the old weights to the new linear layer\n",
    "new_ffw_layer.weight.data[:old_vocab_size] = mfoo.ffw.weight.data[:old_vocab_size]\n",
    "\n",
    "# Initialize the new weights for the new vocabulary\n",
    "new_ffw_layer.weight.data[old_vocab_size:] = torch.randn(new_vocab_size - old_vocab_size, embedding_dim)\n",
    "\n",
    "# Replace the old Linear layer (self.ffw) with the new one\n",
    "mfoo.ffw = new_ffw_layer\n",
    "\n",
    "# Now your model (mfoo) is updated and ready for fine-tuning with the new vocabulary size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6q801ztt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fd21e31f644171ae12bb8600c1416c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine_tuning_skipgram</strong> at: <a href='https://wandb.ai/omareweis123/skipgram_training/runs/6q801ztt' target=\"_blank\">https://wandb.ai/omareweis123/skipgram_training/runs/6q801ztt</a><br/> View project at: <a href='https://wandb.ai/omareweis123/skipgram_training' target=\"_blank\">https://wandb.ai/omareweis123/skipgram_training</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241022_113704-6q801ztt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6q801ztt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\omare\\Desktop\\hackernews llm project\\two_towers\\wandb\\run-20241022_114055-1h0jb7s0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/omareweis123/skipgram_training/runs/1h0jb7s0' target=\"_blank\">fine_tuning_skipgram</a></strong> to <a href='https://wandb.ai/omareweis123/skipgram_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/omareweis123/skipgram_training' target=\"_blank\">https://wandb.ai/omareweis123/skipgram_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/omareweis123/skipgram_training/runs/1h0jb7s0' target=\"_blank\">https://wandb.ai/omareweis123/skipgram_training/runs/1h0jb7s0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import more_itertools\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"skipgram_training\", entity=\"omareweis123\", name='fine_tuning_skipgram')\n",
    "\n",
    "# Set parameters\n",
    "batch_size = 200\n",
    "learning_rate = 0.001 # Define your learning rate\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mFoo = mfoo.to(device)\n",
    "\n",
    "# Set context size\n",
    "context_size = 2  # Example context size\n",
    "window_size = 2 * context_size + 1  # Total tokens in the window\n",
    "\n",
    "# Initialize the optimizer\n",
    "opFoo = torch.optim.Adam(mFoo.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Create your new dataset (make sure tokens are prepared)\n",
    "# Assume new_tokens is your new dataset's tokenized input\n",
    "wins = list(more_itertools.windowed(new_token_ids, window_size))  # Create sliding windows for the new dataset\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    prgs = tqdm.tqdm(range(0, len(wins), batch_size), total=len(wins) // batch_size, desc=f\"Epoch {epoch + 1}\", leave=False)\n",
    "\n",
    "    total_loss = 0.0  # Initialize total loss for the epoch\n",
    "    num_batches = 0   # Counter for batches\n",
    "\n",
    "    for batch_idx in prgs:\n",
    "        batch_wins = wins[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "        # Prepare batch inputs and targets\n",
    "        inpts = torch.LongTensor([win[context_size] for win in batch_wins]).to(device)  # Central token for each window\n",
    "        trgs = torch.LongTensor([[win[i] for i in range(context_size)] + [win[i] for i in range(context_size + 1, window_size)]\n",
    "                                  for win in batch_wins]).to(device)  # Context tokens (left and right)\n",
    "        rand = torch.randint(0, len(vocab_dict), (batch_size, 2)).to(device)  # Random negative samples\n",
    "\n",
    "        # Zero gradients\n",
    "        opFoo.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        loss = mFoo(inpts, trgs, rand)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        opFoo.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Log the loss\n",
    "        wandb.log({'loss': loss.item(), 'learning_rate': learning_rate})\n",
    "\n",
    "    # Calculate and log average loss for the epoch\n",
    "    average_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    wandb.log({'average_loss': average_loss})\n",
    "\n",
    "# Finish the W&B logging\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
